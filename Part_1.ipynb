{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should just be main.py from my file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Will\\PycharmProjects\\FE690_HW1\\data_generation_functions.py:21: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 80 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Will\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/10\n",
      "320/320 [==============================] - 0s 413us/sample - loss: 8.4229 - categorical_accuracy: 0.2375 - val_loss: 8.3626 - val_categorical_accuracy: 0.5125\n",
      "Epoch 2/10\n",
      "320/320 [==============================] - 0s 59us/sample - loss: 8.4505 - categorical_accuracy: 0.6531 - val_loss: 8.3762 - val_categorical_accuracy: 0.6875\n",
      "Epoch 3/10\n",
      "320/320 [==============================] - 0s 56us/sample - loss: 8.4476 - categorical_accuracy: 0.6531 - val_loss: 8.3762 - val_categorical_accuracy: 0.2250\n",
      "Epoch 4/10\n",
      "320/320 [==============================] - 0s 59us/sample - loss: 8.4660 - categorical_accuracy: 0.1688 - val_loss: 8.4427 - val_categorical_accuracy: 0.2000\n",
      "Epoch 5/10\n",
      "320/320 [==============================] - 0s 62us/sample - loss: 8.5280 - categorical_accuracy: 0.1844 - val_loss: 8.4949 - val_categorical_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "320/320 [==============================] - 0s 59us/sample - loss: 8.5442 - categorical_accuracy: 0.2406 - val_loss: 8.5427 - val_categorical_accuracy: 0.3375\n",
      "Epoch 7/10\n",
      "320/320 [==============================] - 0s 59us/sample - loss: 8.5806 - categorical_accuracy: 0.4500 - val_loss: 8.5617 - val_categorical_accuracy: 0.6750\n",
      "Epoch 8/10\n",
      "320/320 [==============================] - 0s 56us/sample - loss: 8.5940 - categorical_accuracy: 0.7063 - val_loss: 8.5564 - val_categorical_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "320/320 [==============================] - 0s 56us/sample - loss: 8.5965 - categorical_accuracy: 0.7406 - val_loss: 8.5625 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "320/320 [==============================] - 0s 94us/sample - loss: 8.6086 - categorical_accuracy: 0.7500 - val_loss: 8.5778 - val_categorical_accuracy: 0.7375\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "This is the main file for HW 1 of FE 690\n",
    "Author: Will Long, MS\n",
    "Date: 09/15/2019\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import data_generation_functions as dgf\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "\n",
    "''' First, we need to make the data.'''\n",
    "\n",
    "data_1 = dgf.create_dataset_00()\n",
    "data_2 = dgf.create_dataset_01()\n",
    "\n",
    "'''Now, we need to the actual modeling.'''\n",
    "\n",
    "km_1 = KMeans(n_clusters=4, random_state=0).fit(data_1)\n",
    "km_2 = KMeans(n_clusters=3, random_state=0).fit(data_2)\n",
    "\n",
    "db_1 = DBSCAN(eps=0.25, min_samples= 5).fit(data_1)\n",
    "db_2 = DBSCAN(eps=0.5, min_samples= 2).fit(data_2)\n",
    "\n",
    "'''Now, we need to try and make the tensorflow model.'''\n",
    "\n",
    "model_km = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model_km.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "                 loss=tf.keras.losses.categorical_crossentropy,\n",
    "                 metrics=[tf.keras.metrics.categorical_accuracy])\n",
    "\n",
    "'''Now, we need to make the dataset for TF.'''\n",
    "labels_1 = km_1.labels_\n",
    "labels_2 = km_2.labels_\n",
    "\n",
    "\n",
    "t_data_1, v_data_1, t_label_1, v_label_1 = train_test_split(data_1, labels_1, test_size=0.2)\n",
    "t_data_2, v_data_2, t_label_2, v_label_2 = train_test_split(data_2, labels_2, test_size=0.2)\n",
    "\n",
    "model_km.fit(t_data_1, t_label_1, epochs=10, batch_size=32, validation_data=(v_data_1, v_label_1))\n",
    "result_labels_1 = model_km.predict(data_1)\n",
    "\n",
    "def labelmaker(x):\n",
    "    '''\n",
    "    This should take the 2-D labels from result_labels and turn it into a 1-D array we can use for graphing.\n",
    "    :param x: 2-D array\n",
    "    :return: 1-D array\n",
    "    '''\n",
    "    a = []\n",
    "    for i in range(0,len(x)):\n",
    "        a.append(np.argmax(x[i]))\n",
    "    return a\n",
    "\n",
    "graph_labels_1 = labelmaker(result_labels_1)\n",
    "\n",
    "def point_classifier_tf(x):\n",
    "    '''\n",
    "    This should take a 2-D point and classify it as one of the clusters from KMeans.\n",
    "    :param x: 2-tuple \n",
    "    :return: Int. label from 0 to 3\n",
    "    '''\n",
    "    x_a = np.array([x,[0 , 0]])    # I don't know why I have to do this, but it works.\n",
    "    a = model_km.predict(x_a)\n",
    "    b = labelmaker(a)\n",
    "    return b[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    print(point_classifier_tf(data_1[7]))\n",
    "\n",
    "    plt.subplot(231)\n",
    "    plt.scatter(data_1[:, 0], data_1[:, 1], c=km_1.labels_, cmap='viridis')\n",
    "    plt.title('Data 1: Kmean; 4 clusters')\n",
    "    plt.subplot(232)\n",
    "    plt.scatter(data_2[:, 0], data_2[:, 1], c=km_2.labels_, cmap='viridis')\n",
    "    plt.title('Data 2: Kmean; 3 clusters')\n",
    "    plt.subplot(233)\n",
    "    plt.scatter(data_1[:, 0], data_1[:, 1], c=db_1.labels_, cmap='viridis')\n",
    "    plt.title('Data 2: DBSCAN; eps=0.25, min_samples= 5')\n",
    "    plt.subplot(234)\n",
    "    plt.scatter(data_2[:, 0], data_2[:, 1], c=db_2.labels_, cmap='viridis')\n",
    "    plt.title('Data 2: DBSCAN; eps=0.5, min_samples= 2')\n",
    "    plt.subplot(235)\n",
    "    plt.scatter(data_1[:, 0], data_1[:, 1], c=graph_labels_1, cmap='viridis')\n",
    "    plt.title('Data 1: Tf-Kmean; 4 clusters')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
